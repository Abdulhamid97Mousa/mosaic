# Day 5 – Current Design Errors and Proposed Solutions

## WHY: Surface regressions before scaling beyond toy-text
- **Stop toy-text bias:** Rendering, caching, and logging assumptions all lean on FrozenLake/CliffWalking/Taxi grids. Box2D games introduce RGB frames, >1 MB payloads, and continuous control; we need guardrails now, not after the port starts.
- **Guarantee replayability:** Researchers expect to rewind any episode with action metadata, frame hashes, and RNG seeds intact. The current runtime log only holds coarse status strings, so the replay narrative collapses after a session ends.
- **Bound storage cost:** Without an explicit persistence policy (`var/` or similar), frame dumps will eventually saturate the repo or an unlucky SSD. We must stage tiered storage and make pruning rules explicit.

## WHAT: Design errors blocking multi-environment support
Each finding follows the structure **(Priority ▸ Risk ▸ Contrarian pressure test ▸ Recommendation)** so we keep the debate explicit.

1. **Rendering strategy coupled to toy-text**  ▸ **Priority: Critical**
   - **Risk:** `GridRenderer` clears and rebuilds the entire scene per step, assumes ASCII payloads, and never negotiates render mode (`RenderMode.RGB_ARRAY`). Box2D environments emit RGB arrays (96×96×3 CarRacing, 400×600×3 LunarLander); naïvely converting to ANSI grids is both lossy and CPU bound.
   - **Contrarian question:** *What if we stay grid-only until Box2D work actually starts?* Answer: the moment an adapter returns `RenderMode.RGB_ARRAY`, the UI crashes or silently displays garbage. Worse, any short-term hacks (e.g., PIL-to-ANSI conversion) will become debt we delete later.
   - **Recommendation:** Split rendering behind an interface now (see §HOW.1) and enforce render-mode negotiation in CI so toy-text shortcuts cannot regress Box2D readiness.

2. **No frame persistence contract**  ▸ **Priority: High**
   - **Risk:** `runtime/data/toy_text` hardcodes text snapshots. There is no general-purpose writer, no hashing, and no storage directory separate from tracked assets. Qt’s `QImage`/`QVideoFrame` remain unused even though they give us GPU-friendly surfaces tailor-made for RGB frames.
   - **Contrarian question:** *Can’t we rely on external tooling (Gym wrappers, screen recorders) to capture frames?* That shifts responsibility to users and breaks reproducibility: headless agents and CI runs have no GUI to capture.
   - **Recommendation:** Define a storage contract (`AdapterStep.frame_ref` + recorder service) with pluggable back ends so both toy-text and Box2D adapters can persist frames uniformly.

3. **Directory layout lacks a writable `var/` tier**  ▸ **Priority: Medium**
   - **Risk:** Day 0 blueprint called for a storage service, yet there is no `var/`, `runtime/records/`, or retention policy. Shared workstations need predictable cleanup knobs.
   - **Contrarian question:** *Why not keep using `runtime/`?* Because mixing writable artifacts with versioned assets invites accidental commits and makes pruning hard.
   - **Recommendation:** Establish `var/` with retention guards (see §HOW.5) before Box2D adapters ship; otherwise their test suites will litter repositories and CI.

4. **Static-analysis debt piling up (cyclomatic, dead stores, asset dispatch)** ▸ **Priority: Medium**
   - **Risk:** `create_adapter` (cyclomatic 9) and `RenderView.display` (cyclomatic 11) both exceed the lint threshold while importing adapters inline; adding LunarLander or RGB renderers will push them further into “hard to test” territory. `ToyTextAdapter._agent_position_from_state` keeps an unused `height` variable and swallows every exception, and `TaxiAssets.get_tile_asset` nests five layers of branching to infer wall caps—once RGB assets arrive this becomes unmaintainable.
   - **Contrarian question:** *They’re only slightly over budget—why burn time now?* Because we already saw CliffWalking regressions hidden by the blanket `except` and we’ll need to touch these functions when we introduce Box2D. Paying back the debt while the modules are still toy-text only keeps future refactors surgical instead of emergency surgery.
   - **Recommendation:** Split `create_adapter` with a `_instantiate_with_config` helper and move imports to module scope; refactor `RenderView.display` into `_display_grid_payload` and `_display_text_payload` helpers that assert supported render modes; drop the dead store in `toy_text.py`, replace the blanket catch with explicit logging, and flatten taxi asset dispatch behind data tables before adding RGB tiles.

5. **No first-class video capture or replay pipeline** ▸ **Priority: High**
   - **Risk:** Live Qt rendering never persists to disk, so researchers cannot attach gameplay evidence to papers or share reproducible demonstrations. CleanRL ships video writers by default; we currently ask users to screen-record manually, breaking automation and CI.
   - **Contrarian question:** *Can’t we punt until after Box2D lands?* Waiting means retrofitting capture into already-complex controllers. Capturing frames while APIs are still fresh lets StorageRecorder own the responsibility and keeps replay tooling consistent across environment families.
   - **Recommendation:** Extend `StorageRecorderService` to encode frames (PNG/WebP/MP4), associate them with `AdapterStep.frame_ref`, and add a replay CLI/Qt tab that plays back recorded episodes. Ensure capture runs headless via `RecordVideo`-style wrappers for parity with CleanRL.

6. **Experiment telemetry lacks research-grade sinks** ▸ **Priority: Medium**
   - **Risk:** Metrics stay trapped in the UI log; there is no TensorBoard summary writer, no Weights & Biases integration, and no API for experiment tagging. Teams cannot aggregate across sessions or compare against baseline algorithms.
   - **Contrarian question:** *Do solo learners really need W&B?* Maybe not today, but the moment we court external contributors or benchmark agents, lack of standardized logging becomes a blocker. CleanRL’s adoption comes from frictionless experiment tracking—we should plan similar hooks.
   - **Recommendation:** Design a telemetry export layer that can stream scalar summaries to TensorBoard and optionally to W&B/MLflow. Gate behind settings so casual users are not forced into accounts, but keep the interface ready for research workflows.

7. **Dependency management still ad-hoc** ▸ **Priority: Medium**
    - **Risk:** Dependencies live in a loose `requirements.txt` with unpinned versions; no lockfile exists. Two contributors may install different Qt or Gymnasium builds and hit inconsistent bugs. Packaging for CI or reproducible research is impossible without a deterministic environment.
    - **Contrarian question:** *Isn’t `pip install -r requirements.txt` good enough?* Not once Box2D, GPU libraries, or headless runners join the mix. CleanRL proves that pinning via Poetry/uv keeps environments aligned across thousands of runs.
    - **Recommendation:** Migrate to a managed environment (`pyproject.toml` + `poetry.lock` or `uv.lock`), pin minimum versions, and document the setup path. Update CI to validate the lockfile so drift is caught immediately.

8. **No automated formatting or linting gate** ▸ **Priority: Medium**
    - **Risk:** Without pre-commit hooks (black, isort, pyupgrade, autoflake, codespell), style drift and unused code accumulate. Large diffs slow reviews and hide regressions—exactly what CleanRL avoids with mandatory hooks.
    - **Contrarian question:** *Can’t reviewers enforce style manually?* Manual policing burns reviewer time and still lets issues slip through. Automation keeps the repo consistent and frees humans to focus on logic.
    - **Recommendation:** Adopt a `.pre-commit-config.yaml` mirroring CleanRL’s stack, wire it into CI, and document the workflow so every contributor runs the hooks locally before pushing.

## Resolved design risks since last review

- **Unified human-input gating:** `gym_gui/ui/main_window.py` now funnels all control-flow transitions through `_update_input_state()`, which reads `_game_started`, `_game_paused`, and `_awaiting_human` before toggling `HumanInputService` shortcuts and control-panel affordances. This closes the duplication that previously allowed “frozen start” regressions in Box2D environments.
- **Shared discrete→continuous action mapping:** `gym_gui/services/action_mapping.py` and the refactored Box2D adapters (`gym_gui/core/adapters/box2d.py`) centralise keyboard-to-`Box` conversions. Mappings are registered during bootstrap so LunarLander, BipedalWalker, and CarRacing all consume the same tables without bespoke helper methods.

## HOW: Concrete fixes (contrarian stance included)
### 1. Rendering abstraction split
- **Short-term (toy-text still supported):**
  - Keep `GridRenderer` but move it behind `IRendererStrategy` with `render(payload: AdapterStep, target: QGraphicsView)`.
  - Add `RgbFrameRenderer` using `QImage` + `QVideoFrame` for Box2D frames; map `RenderMode.RGB_ARRAY` to it via factory.
- **Why bother now?** Because reusing the toy-text grid path for Box2D will force ugly ANSI emulation layers. Two renderers keep the code honest and let us benchmark memory separately.

### 2. Adapter contract extensions
- Add `AdapterStep.frame_ref` (nullable) that points to an immutable record (hash, path, metadata). Toy-text adapters can skip it; Box2D adapters will populate it once the storage service writes the frame.
- Extend `EnvironmentAdapter.render()` to return either structured grid data **or** raw RGB frames with metadata (shape, dtype, timestamp). Enforce this with `TypedDict` to avoid silent mismatches.

### 3. Storage service with configurable tiers
- Introduce `gym_gui/storage/recorder.py` implementing:
  - **Ring buffer** (in-memory `deque`, default 512 frames) for quick replay.
  - **Disk writer** targeting `var/records/<session_id>/frame_<step>.png` or `.bgr` (depends on codec). Disk path should be `.gitignore`d and user-configurable.
  - **Optional writer hook** to send frames to external sinks (e.g., database, message queue) without blocking the UI thread.
- Compose the recorder via `SessionController` so every `AdapterStep` is logged alongside timestamp, action, reward, termination flags.

### 4. Logging revamp
- Replace the text-only log pane with a structured model (`QAbstractTableModel`) feeding a `QTableView` with columns: step, action, reward, terminated, truncated, elapsed ms, frame hash.
- Persist logs as newline-delimited JSON (NDJSON) in `var/records/<session_id>/episode_<n>.jsonl`. This scales to millions of steps and compresses nicely.

### 5. Directory and retention policy
- Create top-level `var/` with subfolders:
   - `var/cache/` – transient derived assets (respects `.gitignore`).
   - `var/records/` – per-session logs, frames, metadata.
   - `var/tmp/` – scratch space for exporters.
- Add retention options in settings:
   - `max_record_bytes` (default 2 GB).
   - `max_sessions` (sliding window).
   - `prune_on_start` boolean.
- Build a CLI `python -m gym_gui.tools.prune --dry-run` mirroring how `openshot-qt` cleans render caches.

## ADDITIONAL BACKLOG FROM FULL CODEBASE AUDIT
| Finding | Evidence | Contrarian pressure test | Path to resolution |
| --- | --- | --- | --- |
| `create_adapter` and `RenderView.display` over cyclomatic budget | • `gym_gui/core/factories/adapters.py:33-69` (cyclomatic ≈ 9) branches on each adapter type and performs runtime imports.<br>• `gym_gui/ui/main_window.py:520-566` interleaves payload parsing with UI tab toggles, leaving `game_id_str` unused. | *“They’re only one point over—why touch them?”* Box2D adapters will add new render modes and options, pushing both functions further over budget and making bugs harder to isolate during a crunch. | • Extract `_instantiate_with_config(adapter_cls, game_config)` helper and eliminate intra-function imports.<br>• Split `RenderView.display` into `_display_grid_payload` / `_display_text_payload`, drop dead variables, and add render-mode assertions. |
| `toy_text.py` dead stores and blanket catch | `gym_gui/core/adapters/toy_text.py:313` sets `height = 4` but never uses it; the surrounding `except Exception: return None` masks decode regressions. | *“Unused variable doesn’t break production.”* True today, but the dead store already hid a CliffWalking rendering bug last sprint; keeping it invites repeat regressions when grid sizes change. | Remove the dead assignment; replace the blanket `except` with `except Exception as exc:` that logs state + adapter ID before returning `None`. |
| `AssetManager.get_tile_asset` complexity | `gym_gui/rendering/assets.py:120-266` nests Taxi/FrozenLake/CliffWalking conditionals, with Taxi medians hard-coded. | *“Medium severity is fine.”* Once Box2D assets arrive the branching doubles, and current tests won’t cover missing sprites. | Move environment-specific lookups into `FrozenLakeAssets`, `TaxiAssets`, and `CliffWalkingAssets` static maps; keep dispatcher minimal and add unit tests asserting asset coverage per environment. |
| Storage helpers silently create `var/data` only | `gym_gui/storage/filesystem.py` writes JSON to `var/data` but exposes no retention, collision strategy, or linkage to runtime/session artifacts. | *“At least we have `var/` now.”* Without aligning this with the recorder plan, Box2D frame dumps will still flood `runtime/`. | Fold the helper into `StorageRecorder`, ensuring `var/records`, `var/cache`, and quotas are created and monitored at startup. |

## STATUS VS. DAY 4 QT SHELL PLAN
| Day 4 expectation | Evidence in repo | Gap today | Next action |
| --- | --- | --- | --- |
| **Layered rendering strategy** (§14) promised a split between logic, assets, and paint routines with an RGB-ready pathway. | `RenderView` still instantiates `GridRenderer` directly and toggles tabs based on dict keys; no RGB handler exists. | Rendering remains single-path and blocks Day 4 “layered renderer” milestone. | Complete §HOW.1 renderer split, add smoke test for `RenderMode.RGB_ARRAY`, and document the tab-switch handoff. |
| **Panel wiring cleanup** (§3, §5) called for presenter-driven signal maps and removal of inline Qt hookups. | `MainWindow._connect_signals()` still binds dozens of slots manually; presenter only re-emits a subset. | `_update_input_state()` now centralises human-input gating, but signal wiring remains in `MainWindow`, so presenter separation is still pending. | Migrate the unified control-state helper into the presenter and collapse direct signal hookups in `MainWindow`. |
| **Hybrid control modes** (§6.3) assumed actors could be swapped to enable agent parity. | No `Actor` protocol exists; `SessionController._select_agent_action()` samples space directly. | Actor abstraction is missing, contradicting Day 4 parity objective. | Implement actor registry per Finding #5 and persist actor metadata with `StepRecord`. |
| **Telemetry table upgrade** (§8) highlighted moving from log textarea to structured model with export controls. | `MainWindow` still appends plain text via `_append_log_record`; there is no export. | Researchers can’t filter or export logs, failing Day 4 QA plan. | Prioritize Phase 3 telemetry revamp with NDJSON writer and `QTableView` integration. |
| **Resource tooling** (§11) insisted on working `rcc`/Qt resource pipeline. | VS Code generated `gym_gui/gym_gui` demo folder and `*.qrc` files still fail compilation (no `rcc` path set). | Resource pipeline remains brittle; we copy PNGs manually. | Configure `qtForPython.PyQt6.rccPath` to `/usr/lib/qt6/libexec/rcc`, clean demo artifacts, and add CI check that `.qrc` builds succeed. |

## SERVICE ROADMAP

### What we have
`gym_gui.services` now houses `TelemetryService`, `StorageRecorderService`, `ActorService`, and the new `ContinuousActionMapper`, which collectively keep telemetry, persistence, orchestration, and action translation out of the controllers. We still rely on `SessionController` for wiring, but the service locator pattern is in place.

### Immediate services to define
- **Harden existing Actor/Telemetry/Storage services** — expand test coverage, expose configuration hooks, and document lifecycle management now that the services are live.
- **ResourceCompilerService** — wraps Qt’s `rcc`, validates `.qrc` bundles at startup, and feeds future packaging steps (inspired by fbs’s asset pipeline and Qt Multimedia docs on `QVideoFrame`/`QVideoRendererControl`).
- **SettingsService / AppContext** — centralizes `get_settings()` overrides, caches derived values, and coordinates service startup the way `CuraApplication` wires its subsystems.

### Execution steps
1. Draft service interfaces (protocols/dataclasses) inside `gym_gui/services/__init__.py`.
2. Inject services into `MainWindowPresenter` and `SessionController` via a lightweight service locator (no external DI required yet).
3. Add integration tests under `tests/services/` to cover actor fallbacks, recorder retention, and telemetry publishing.

## VAR/DATA STRUCTURE PLAN

### Desired layout
```
gym_gui/
   var/
      records/
         <session_id>/
            metadata.json
            steps.sqlite        # telemetry + frame index
            frames/
               frame_000001.png
      cache/
         renderer/
      tmp/
```

### Action items
- **Session bootstrap** — StorageRecorderService stamps a session ID, writes metadata (env, seed, control mode, active actors), and initializes telemetry storage.
- **Retention job** — background worker scans `records/` and `cache/`, prunes according to settings, and logs the summary via TelemetryService.
- **Testing hooks** — add `python -m gym_gui.tools.prune --dry-run` to CI so retention rules stay honest.
- **Docs & README updates** — describe writable areas, `.gitignore` coverage, and expected disk usage, borrowing language from the storage table below.
- **Sample artifact** — generate a miniature NDJSON + PNG pair during tests so downstream tooling has a canonical reference format.

## ENV_ADAPTERS EXPANSION

### Targets
- Relocate toy-text adapters into `env_adapters/toy_text`, keeping `core.adapters` focused on abstract bases and factories.
- Establish a plugin-style registry (à la Cura’s `plugins/`) for future Box2D, Atari, or user-supplied adapters.

### Steps
- **Package layout** — introduce `env_adapters/registry.py`, subpackages per environment family, and move `toy_text_demo` alongside its adapters.
- **Registry changes** — shift `_registry()` into `env_adapters.registry`, support directory-based discovery, and surface metadata (render modes, control modes, storage profile) to the UI.
- **Configuration** — define `adapter.yaml` manifests (inspired by Cura’s machine definitions) and a validation helper.
- **Testing & examples** — provide `demo.py` per adapter family and acceptance tests that load adapters through the new registry.
- **Docs** — update Day 4/5 docs and author `docs/env_adapter_guide.md` to guide contributors, taking cues from Cura’s plugin wiki.

## CROSS-CUTTING LEARNINGS FROM REFERENCE REPOS
- **Cura** — demonstrates modular services, backup flows, and plugin registries we can mirror in `services/` and `env_adapters/`.
- **fbs tutorial** — illustrates a PyQt app context managing resources and stylesheets; we can adapt the pattern for our Settings/Resource services.

## NEXT STEPS CHECKLIST
1. Sketch the service interfaces and wiring plan under `gym_gui/services/`.
2. Prototype StorageRecorder writing into `var/records` (frames + SQLite telemetry) and confirm retention tooling.
3. Restructure adapters into the new package layout and update factory imports.
4. Update documentation (this memo, Day 4 plan, adapter guide) with the new architecture.
5. Evaluate packaging (fbs/PyInstaller) once services settle, leveraging ResourceCompilerService.

## STORAGE PLAN BY ENVIRONMENT FAMILY

Even in agent-only runs, we record the exact same artifacts we capture for human sessions—frame-perfect parity keeps comparisons fair and enables offline evaluation.

| Game family | Payload profile | Storage strategy | Retention + notes |
| --- | --- | --- | --- |
| **Toy-text** (FrozenLake, CliffWalking, Taxi, etc.) | ANSI grids only; <5 KB per step; episodes typically <500 steps. | Keep entire episode in an in-memory ring buffer, persist telemetry in `steps.sqlite`, and optionally dump ANSI text snapshots (`var/records/<session>/ansi/episode.txt`). | Default: keep 10 sessions, prune snapshots older than 7 days. Human and agent play share the same recording path. |
| **Box2D / physics (LunarLander, BipedalWalker, CarRacing)** | RGB frames 20–100 KB compressed; 30–60 FPS auto-play. | Hybrid pipeline: ring buffer of latest 256 frames for instant rewind, async PNG/WebP encoder writing into `frames/`, telemetry tracked in SQLite with `frame_ref` (relative path + checksum). | Guard with `max_record_bytes` (≈2 GB) and optional `keep_every_n_frames` downsampling after long runs. |
| **Atari / high-frame-count pixel games** | 160×210 or similar frames; >100 k steps per experiment. | Use SQLite (`steps.sqlite`) with BLOB columns for compressed PNG/WebP chunks plus side tables for metadata (width/height/channels). Batch frames into blobs (e.g., 256-step segments) to avoid millions of files. Provide CLI to export subsets as PNG when needed. | Rotate to a new SQLite archive after `max_frames_per_archive`; default prune keeps 3 complete sessions. |
| **3D / external simulators (MuJoCo, Isaac Gym, robotics)** | HD textures; potential GPU surfaces. | Stream-first: forward frames to an external recorder (ZeroMQ/HTTP) that writes MP4 or custom archives. Locally keep keyframes in `var/cache/preview/` (capped at 500 MB). | External pipeline defines retention; our settings expose endpoint + preview cache size. |
| **Telemetry-only adapters** (statistics feeds, diagnostics) | No native frames but still want parity with agent runs. | Record `steps.sqlite` (actions, rewards, timers) and attach user-supplied hooks for downstream sinks. Frames columns remain empty but schema stays consistent. | Same prune behaviour as toy-text; optional CSV export for quick sharing. |

### Settings integration
- Store storage profiles in `gym_gui/config/storage_profiles.yaml` (YAML keeps it approachable, mirrors Cura’s configuration files).
- Extend `Settings` with a `storage_profile` lookup that falls back to `toy_text` when an adapter does not specify a profile.
- Each adapter declares `storage_profile` in its manifest (e.g., toy-text → `toy_text`, Box2D → `box2d`, Atari → `atari_sqlite`).
- StorageRecorderService loads the YAML at startup, validates required keys, and exposes helper methods (`profile.for_frames()`, `profile.for_telemetry()`).

This approach reuses familiar technologies—PNG for images, SQLite for telemetry and high-frame-count archives, YAML for configuration—while still leaving room for optional upgrades (GPU encoders, external streaming) if future workloads demand them.

## AGENT ARCHITECTURE & AGENT-ONLY MODE

We need Agent Only mode to support both a high-volume BDI/Q-learning learner (thousands of autonomous episodes) and multi-step LLM agents that drive the game via snapshot-based reasoning. The plan below wires both agent types into the forthcoming services stack while keeping storage manageable.

### 1. BDI + Q-learning Agent
- **Actor definition**: Implement `BDIQAgent` inside `gym_gui/services/actors/bdi.py` with methods `select_action(step_record)`, `on_step(step_record)`, and `on_episode_end(stats)`. The actor owns a Q-table (or neural approximator), exploration policy, and belief tracker.
- **Control flow**: In Agent Only mode, `SessionController.perform_agent_step()` always delegates to ActorService. Auto-play timer stays engaged with a configurable interval (`settings.agent_step_interval_ms`) so headless training can run at high speed.
- **Experience capture**: StorageRecorderService segments each session into `episode_<n>/` directories containing:
   - `transitions.sqlite` (state, action, reward, next_state, TD error, Q deltas). Use WAL mode for streaming inserts.
   - Optional key-frame PNGs governed by the environment’s storage profile (`keep_every_n_frames`, `store_reward_spikes_only`).
   - `metrics.json` summarizing episode reward, epsilon, alpha, convergence signals.
- **Replay buffer**: Provide `services/experience.py` to persist prioritized experience replay in SQLite (indexed by TD error, visitation count) so training can resume mid-run.
- **Scaling to 5 000+ episodes**: Introduce `max_episodes_per_archive` to roll telemetry into a new subfolder when a threshold is reached. Add `storage.prune_bdi_rollups` CLI that compresses older `transitions.sqlite` files or exports them to parquet for archival.
- **Monitoring**: TelemetryService emits aggregated stats every N episodes (moving average reward, epsilon, success rate). MainWindow (or headless CLI) can display progress or export CSV snapshots.

### 2. LLM Multi-Step Agent
- **Tool-enabled actor**: Add `LLMMultiStepAgent` under `services/actors/llm.py`. The actor coordinates with a ToolService exposing `request_snapshot()` and `query_status()` helpers.
- **Snapshot pipeline**: StorageRecorderService exposes `capture_snapshot(session_id, episode, step)` which renders one frame to `var/records/<session>/snapshots/` and returns a deduplicated hash. The actor packages the snapshot path/base64 plus textual context for the LLM.
- **Rate limiting & batching**: ToolService enforces cooldowns (e.g., max X snapshots per second) and encourages plan-ahead prompts (observe → plan 3 moves → execute) to contain API usage.
- **Telemetry**: Store LLM prompt/response hashes, tool usage counts, and resulting action in `llm_decisions` table within `transitions.sqlite`. Optionally persist truncated reasoning logs for debugging (configurable via settings).
- **Data minimization**: Snapshots honor the environment’s storage profile. For `toy_text`, skip image capture; for Box2D, keep only LLM-requested frames. Provide `settings.llm_snapshot_retention` to purge snapshot directories once review is done.

### 3. Shared Infrastructure Updates
- **ActorService**: Gain registration APIs and prioritized selection. `SessionController` requests the active actor each step; for hybrid modes we can still coordinate humans + agents later.
- **CLI tooling**: Add `python -m gym_gui.run_agent --agent bdi --env LunarLander-v2 --episodes 5000` for headless training and `--agent llm --snapshot-provider qt` for vision-driven runs. Both reuse StorageRecorderService so storage policies stay consistent.
- **Settings additions**: Extend YAML profiles with agent-specific knobs (`max_episodes_per_archive`, `snapshot_deduplication`, `episode_rollup_policy`). Provide defaults tuned per environment family.
- **Retention strategies**: Implement `EpisodeRollupJob` that compresses old episodes, merges statistics, and prunes low-value transitions (e.g., TD error below threshold) while keeping key events.

### 4. Data Volume Guardrails
- Downsample frames aggressively for long BDI runs (keep first, goal-reaching, and reward-spike frames).
- Hash snapshots and store only unique frames for LLM agents; reference duplicates via metadata.
- Compress telemetry archives (gzip SQLite backups or export to parquet) once episodes are inactive.
- Maintain metadata indexes (`episode_index.json`) tracking reward trends, enabling quick filtering without loading entire archives.

This roadmap ensures Agent Only mode is ready for both autonomous RL training and vision-powered reasoning agents, while StorageRecorderService + TelemetryService absorb the data volume without overwhelming disks or the UI.

## PRIORITIZED ROADMAP (12-week view)
| Phase | Horizon | Key Outcomes | Owners | Acceptance Tests |
| --- | --- | --- | --- | --- |
| **Phase 0 – Hardening** | Week 0 (now) | • Restructure Day 4 doc per Day 0–3 style.<br>• Add lint fixes (unused imports, dead variables). | Documentation & core engineering team | ✅ `ruff --select F` passes.<br>✅ Day 4 rewrite approved in review. |
| **Phase 1 – Rendering split** | Weeks 1–2 | • `IRendererStrategy` live with grid + RGB implementations.<br>• Render-mode negotiation enforced in unit test.<br>• Prototype LunarLander adapter feeding RGB frames. | Rendering working group | ✅ Taxi + LunarLander demo toggles renderers without UI crashes.<br>✅ Renderer tests run under `pytest -k rendering`. |
| **Phase 2 – Storage recorder** | Weeks 3–4 | • `var/` scaffolding with pruning CLI.<br>• `StorageRecorder` writing ring buffer + PNG disk snapshots.<br>• `AdapterStep.frame_ref` populated for Taxi + LunarLander. | Storage/telemetry group | ✅ 1 k-step LunarLander session keeps ≤512 frames in RAM, remainder on disk.<br>✅ `python -m gym_gui.tools.prune --dry-run` reports reclaimed bytes. |
| **Phase 3 – Telemetry model** | Weeks 5–6 | • `StepRecord` dataclass persisted as NDJSON.<br>• Log pane upgraded to `QTableView` with filters and export button.<br>• Offline replay CLI consumes stored traces. | UI & telemetry group | ✅ Exported NDJSON replayed via `python -m gym_gui.tools.replay`.<br>✅ Table view filters by action ID < 50 ms latency. |
| **Phase 4 – Scalability & QA** | Weeks 7–12 | • Optionally swap PNG writer for `.zarr` or Parquet pilot.<br>• Add headless regression suite (Taxi + LunarLander) using xvfb.<br>• Introduce metrics dashboard (disk usage, frame write rate). | QA & infrastructure group | ✅ CI job records headless run artifacts.<br>✅ Metrics panel warns when disk quota ≥80 %. |

## STORAGE OPTIONS & TRADE-OFFS
| Option | Pros | Cons | Ideal Use |
| --- | --- | --- | --- |
| **In-memory ring buffer** (`collections.deque`) | Instant replay, no disk I/O, simple to prune. | Volatile; Box2D RGB frames (~150 KB each) eat RAM quickly; restart wipes data. | Live debugging, auto-play visualizations.
| **Disk-backed frame store** (`var/records/*.png` or raw `.bgr`) | Durable, easy to diff/share, compatible with Qt’s `QImage` load/save. | Needs pruning, slower writes unless batched; PNG compression may bottleneck CPU. | Offline review, training datasets, user exports.
| **Memory-mapped binary log** (`mmap`, `.npy`, or `.zarr`) | Random access to large runs, efficient slicing for ML. | Requires schema discipline, tools for viewing; more complex to implement. | Long Box2D rollouts, GPU training pipelines.
| **Database-backed** (SQLite/Parquet via DuckDB) | Rich querying, handles metadata joins (actions, rewards). | Heavy dependency, migration overhead, risk of locking within Qt event loop. | Research teams needing analytics dashboards.

**Qt Multmedia angle:** The Qt docs (`QVideoFrame` in PySide2/PySide6) highlight zero-copy sharing between camera/video pipelines and GPU textures. For Box2D we can wrap `numpy.ndarray` RGB frames into `QVideoFrame` objects, then hand them to a `QVideoSink` or `QGraphicsVideoItem`. This keeps uploads on the GPU and avoids repeated CPU copies when recording or displaying high-FPS content.

## TRADE-OFF SUMMARY
- **Throughput vs. fidelity:** Storing every frame as PNG preserves visuals but costs ~25 MB per CarRacing episode. A raw `.bgr` ring buffer retains fidelity with fixed write cost, but requires custom tooling. Hybrid approach: keep N most recent frames in memory, periodically flush to disk via worker thread.
- **Simplicity vs. scalability:** JSONL logs + PNG frames are easy to implement today and mirror `openshot-qt`’s render cache strategy. However, planning for `.zarr` or Parquet keeps the door open for ML scale. Start with JSONL + PNG, but wrap access behind interfaces so migrations are painless.

## ACTION REGISTER (two-week horizon)
1. **Week 1**
   - Prototype `IRendererStrategy` and plug existing `GridRenderer` into it.
   - Add `RgbFrameRenderer` that consumes ndarray frames, converts to `QImage` or `QVideoFrame`, and benchmarks 60 FPS playback.
   - Stand up `var/` scaffolding with retention CLI and settings toggles.
2. **Week 2**
   - Implement `StorageRecorder` with ring buffer + disk writer.
   - Extend `SessionController` to emit structured `StepRecord` dataclass, wire to log model + NDJSON writer.
   - Adapt Taxi adapter to populate `AdapterStep.frame_ref` (even if it points to a text snapshot) to exercise the API.

## NEXT STEPS + RISKS
- **Risk:** Without early Box2D renderer, the UI team might keep optimizing grids and ignore RGB cases. Mitigation: schedule LunarLander adapter spike immediately after implementing the renderer abstraction.
- **Risk:** Disk usage could balloon if auto-play is left running. Mitigation: expose live disk-usage telemetry in the status panel and add auto-prune thresholds.
- **Checkpoint:** After Week 2 deliverables, run an end-to-end session (Taxi + LunarLander) capturing actions, frames, and logs into `var/records/`, then replay them via a CLI tool to validate the architecture.

## REFERENCES INFORMING THIS PLAN
- **Qt Multimedia (`QVideoFrame`)** – PySide2/PySide6 docs confirm zero-copy frame sharing, guiding the RGB renderer.
- **openshot-qt** – Demonstrates tiered caching (`image_cache.py`), structured logging, and headless testing via xvfb.
- **Day 0–4 docs** – Style guardrails for documentation rewrite (keep tone, heading depth, and conclusion summaries consistent).
