# Lunar Lander Game Note

## Core Facts

- **Objective:** Land a spacecraft safely on the landing pad between the two flags with minimal fuel consumption and gentle velocity.
- **Physics:** Box2D simulation with gravity, thrust, and rotational dynamics.
- **Action space:** Discrete(4) → `0: do nothing`, `1: fire left thruster`, `2: fire main engine`, `3: fire right thruster`.
- **Observation space:** Box(8) continuous vector:
  - `[0]` horizontal position (x)
  - `[1]` vertical position (y)
  - `[2]` horizontal velocity (vx)
  - `[3]` vertical velocity (vy)
  - `[4]` angle
  - `[5]` angular velocity
  - `[6]` left leg ground contact (boolean)
  - `[7]` right leg ground contact (boolean)
- **Episode termination:** Landing (legs touch ground), crashing (body contacts ground), or going out of bounds.

## Reward Structure

| Event | Reward |
| --- | --- |
| Moving toward landing pad | Positive (shaped reward) |
| Moving away from landing pad | Negative (shaped reward) |
| Successful landing | +100 to +140 (depends on softness) |
| Crash | -100 |
| Each leg ground contact | +10 per leg |
| Firing main engine | -0.3 per frame |
| Firing side thrusters | -0.03 per frame |

**Total possible:** Maximum reward ~200-280 for perfect soft landing with minimal fuel.

## Gameplay Dynamics

- **Gravity:** Constant downward force requires active thrust control.
- **Fuel efficiency:** Excessive thruster use penalizes total reward; optimal policies minimize fuel.
- **Soft landing bonus:** Touching down gently (low velocity) yields higher rewards than hard impacts.
- **Orientation control:** Side thrusters rotate the lander; main engine thrust direction depends on angle.
- **Ground contact:** Episode ends when both legs touch (success) or body hits (crash).

## Keyboard Controls (Human Mode)

| Key | Action | Effect |
| --- | --- | --- |
| **Space** | Fire main engine (2) | Thrust downward (relative to lander angle) |
| **A** or **Left** | Fire left thruster (1) | Rotate clockwise |
| **D** or **Right** | Fire right thruster (3) | Rotate counter-clockwise |
| *(no key)* | Do nothing (0) | Coast under gravity |

## Mermaid Flight Sequence

```mermaid
stateDiagram-v2
    [*] --> Spawned: Episode start
    Spawned --> Descending: Gravity pulls down
    Descending --> Adjusting: Fire thrusters
    Adjusting --> Descending: Drift correction
    Adjusting --> Landing: Legs contact ground
    Adjusting --> Crashed: Body hits ground
    Descending --> OutOfBounds: x or y exceeds limits
    Landing --> [*]: +100 to +140
    Crashed --> [*]: -100
    OutOfBounds --> [*]: Episode truncated
    
    note right of Adjusting
        Main engine: -0.3/frame
        Side thrusters: -0.03/frame
    end note
    
    note right of Landing
        +10 per leg contact
        Bonus for soft touchdown
    end note
```

## Training Considerations

1. **Exploration:** Random policies often crash initially; epsilon-greedy or entropy bonus helps discover safe trajectories.
2. **Shaped reward:** Moving toward the pad provides continuous feedback before terminal rewards.
3. **Fuel trade-off:** Agents must balance speed of descent with fuel consumption.
4. **Continuous observations:** Unlike grid games, this requires handling real-valued state vectors.
5. **Discrete actions:** Simpler than continuous thrust control but still requires precise timing.

## Quick Testing Tips

1. **Baseline:** `gym.make("LunarLander-v3")` – standard discrete action space.
2. **Gravity variation:** Use `gravity=-10.0` (default) or adjust for harder/easier landings.
3. **Wind effects:** Enable `enable_wind=True` for stochastic lateral forces (increases difficulty).
4. **Turbulence:** Enable `turbulence_power=1.5` for random thrust noise.
5. **Visual debugging:** Human mode helps understand thruster timing and orientation control.

## Common Pitfalls

- **Ignoring angle:** Firing main engine at steep angles wastes fuel and provides little vertical lift.
- **Over-correction:** Oscillating between left/right thrusters burns fuel without stabilizing.
- **Late braking:** Waiting too long to fire main engine results in hard crashes.
- **Fuel panic:** Constantly firing thrusters prevents coasting and racks up negative rewards.

## References

- Gymnasium documentation – [Lunar Lander](https://gymnasium.farama.org/environments/box2d/lunar_lander/).
- Original OpenAI Gym implementation (2016).
- Box2D physics engine documentation.
    
    Toggle navigation of Wrappers
    
    *   [List of Wrappers](../../../api/wrappers/table/)
    *   [Misc Wrappers](../../../api/wrappers/misc_wrappers/)
    *   [Action Wrappers](../../../api/wrappers/action_wrappers/)
    *   [Observation Wrappers](../../../api/wrappers/observation_wrappers/)
    *   [Reward Wrappers](../../../api/wrappers/reward_wrappers/)
*   [Vectorize](../../../api/vector/)
    
    Toggle navigation of Vectorize
    
    *   [Wrappers](../../../api/vector/wrappers/)
    *   [AsyncVectorEnv](../../../api/vector/async_vector_env/)
    *   [SyncVectorEnv](../../../api/vector/sync_vector_env/)
    *   [Utility functions](../../../api/vector/utils/)
*   [Utility functions](../../../api/utils/)
*   [Functional Env](../../../api/functional/)

### Environments

*   [Classic Control](../../classic_control/)
    
    Toggle navigation of Classic Control
    
    *   [Acrobot](../../classic_control/acrobot/)
    *   [Cart Pole](../../classic_control/cart_pole/)
    *   [Mountain Car Continuous](../../classic_control/mountain_car_continuous/)
    *   [Mountain Car](../../classic_control/mountain_car/)
    *   [Pendulum](../../classic_control/pendulum/)
*   [Box2D](../)
    
    Toggle navigation of Box2D
    
    *   [Bipedal Walker](../bipedal_walker/)
    *   [Car Racing](../car_racing/)
    *   [Lunar Lander](#)
*   [Toy Text](../../toy_text/)
    
    Toggle navigation of Toy Text
    
    *   [Blackjack](../../toy_text/blackjack/)
    *   [Taxi](../../toy_text/taxi/)
    *   [Cliff Walking](../../toy_text/cliff_walking/)
    *   [Frozen Lake](../../toy_text/frozen_lake/)
*   [MuJoCo](../../mujoco/)
    
    Toggle navigation of MuJoCo
    
    *   [Ant](../../mujoco/ant/)
    *   [Half Cheetah](../../mujoco/half_cheetah/)
    *   [Hopper](../../mujoco/hopper/)
    *   [Humanoid](../../mujoco/humanoid/)
    *   [Humanoid Standup](../../mujoco/humanoid_standup/)
    *   [Inverted Double Pendulum](../../mujoco/inverted_double_pendulum/)
    *   [Inverted Pendulum](../../mujoco/inverted_pendulum/)
    *   [Pusher](../../mujoco/pusher/)
    *   [Reacher](../../mujoco/reacher/)
    *   [Swimmer](../../mujoco/swimmer/)
    *   [Walker2D](../../mujoco/walker2d/)
*   [Atari](../../atari/)
*   [External Environments](../../third_party_environments/)

### Tutorials

*   [Gymnasium Basics](../../../tutorials/gymnasium_basics/)
    
    Toggle navigation of Gymnasium Basics
    
    *   [Make your own custom environment](../../../tutorials/gymnasium_basics/environment_creation/)
    *   [Handling Time Limits](../../../tutorials/gymnasium_basics/handling_time_limits/)
    *   [Implementing Custom Wrappers](../../../tutorials/gymnasium_basics/implementing_custom_wrappers/)
    *   [Load custom quadruped robot environments](../../../tutorials/gymnasium_basics/load_quadruped_model/)
*   [Training Agents](../../../tutorials/training_agents/)
    
    Toggle navigation of Training Agents
    
    *   [Action Masking in the Taxi Environment](../../../tutorials/training_agents/action_masking_taxi/)
    *   [Running the Experiment](../../../tutorials/training_agents/action_masking_taxi/#running-the-experiment)
    *   [Visualizing Results](../../../tutorials/training_agents/action_masking_taxi/#visualizing-results)
    *   [Results Analysis](../../../tutorials/training_agents/action_masking_taxi/#results-analysis)
    *   [Solving Blackjack with Tabular Q-Learning](../../../tutorials/training_agents/blackjack_q_learning/)
    *   [Solving Frozenlake with Tabular Q-Learning](../../../tutorials/training_agents/frozenlake_q_learning/)
    *   [Training using REINFORCE for Mujoco](../../../tutorials/training_agents/mujoco_reinforce/)
    *   [Speeding up A2C Training with Vector Envs](../../../tutorials/training_agents/vector_a2c/)
*   [Third-Party Tutorials](../../../tutorials/third-party-tutorials/)

### Development

*   [Github](https://github.com/Farama-Foundation/Gymnasium)
*   [Paper](https://arxiv.org/abs/2407.17032)
*   [Gymnasium Release Notes](../../../gymnasium_release_notes/)
*   [Gym Release Notes](../../../gym_release_notes/)
*   [Contribute to the Docs](https://github.com/Farama-Foundation/Gymnasium/blob/main/docs/README.md)

[Back to top](#)

Toggle Light / Dark / Auto color theme

Toggle table of contents sidebar

Lunar Lander[¶](#lunar-lander "Link to this heading")
=====================================================

 [![../../../_images/lunar_lander.gif](../../../_images/lunar_lander.gif)](../../../_images/lunar_lander.gif) 

This environment is part of the Box2D environments which contains general information about the environment.

### Action Space

`Discrete(4)`

### Observation Space

`Box([ -2.5 -2.5 -10. -10. -6.2831855 -10. -0. -0. ], [ 2.5 2.5 10. 10. 6.2831855 10. 1. 1. ], (8,), float32)`

import

`gymnasium.make("LunarLander-v3")`

Description[¶](#description "Link to this heading")
---------------------------------------------------

This environment is a classic rocket trajectory optimization problem. According to Pontryagin’s maximum principle, it is optimal to fire the engine at full throttle or turn it off. This is the reason why this environment has discrete actions: engine on or off.

There are two environment versions: discrete or continuous. The landing pad is always at coordinates (0,0). The coordinates are the first two numbers in the state vector. Landing outside of the landing pad is possible. Fuel is infinite, so an agent can learn to fly and then land on its first attempt.

To see a heuristic landing, run:

python gymnasium/envs/box2d/lunar\_lander.py

Action Space[¶](#action-space "Link to this heading")
-----------------------------------------------------

There are four discrete actions available:

*   0: do nothing
    
*   1: fire left orientation engine
    
*   2: fire main engine
    
*   3: fire right orientation engine
    

Observation Space[¶](#observation-space "Link to this heading")
---------------------------------------------------------------

The state is an 8-dimensional vector: the coordinates of the lander in `x` & `y`, its linear velocities in `x` & `y`, its angle, its angular velocity, and two booleans that represent whether each leg is in contact with the ground or not.

Rewards[¶](#rewards "Link to this heading")
-------------------------------------------

After every step a reward is granted. The total reward of an episode is the sum of the rewards for all the steps within that episode.

For each step, the reward:

*   is increased/decreased the closer/further the lander is to the landing pad.
    
*   is increased/decreased the slower/faster the lander is moving.
    
*   is decreased the more the lander is tilted (angle not horizontal).
    
*   is increased by 10 points for each leg that is in contact with the ground.
    
*   is decreased by 0.03 points each frame a side engine is firing.
    
*   is decreased by 0.3 points each frame the main engine is firing.
    

The episode receive an additional reward of -100 or +100 points for crashing or landing safely respectively.

An episode is considered a solution if it scores at least 200 points.

Starting State[¶](#starting-state "Link to this heading")
---------------------------------------------------------

The lander starts at the top center of the viewport with a random initial force applied to its center of mass.

Episode Termination[¶](#episode-termination "Link to this heading")
-------------------------------------------------------------------

The episode finishes if:

1.  the lander crashes (the lander body gets in contact with the moon);
    
2.  the lander gets outside of the viewport (`x` coordinate is greater than 1);
    
3.  the lander is not awake. From the [Box2D docs](https://box2d.org/documentation/md__d_1__git_hub_box2d_docs_dynamics.html#autotoc_md61), a body which is not awake is a body which doesn’t move and doesn’t collide with any other body:
    

> When Box2D determines that a body (or group of bodies) has come to rest, the body enters a sleep state which has very little CPU overhead. If a body is awake and collides with a sleeping body, then the sleeping body wakes up. Bodies will also wake up if a joint or contact attached to them is destroyed.

Arguments[¶](#arguments "Link to this heading")
-----------------------------------------------

Lunar Lander has a large number of arguments

\>>> import gymnasium as gym
\>>> env \= gym.make("LunarLander-v3", continuous\=False, gravity\=-10.0,
...                enable\_wind\=False, wind\_power\=15.0, turbulence\_power\=1.5)
\>>> env
<TimeLimit<OrderEnforcing<PassiveEnvChecker<LunarLander<LunarLander-v3>>>>>

*   `continuous` determines if discrete or continuous actions (corresponding to the throttle of the engines) will be used with the action space being `Discrete(4)` or `Box(-1, +1, (2,), dtype=np.float32)` respectively. For continuous actions, the first coordinate of an action determines the throttle of the main engine, while the second coordinate specifies the throttle of the lateral boosters. Given an action `np.array([main, lateral])`, the main engine will be turned off completely if `main < 0` and the throttle scales affinely from 50% to 100% for `0 <= main <= 1` (in particular, the main engine doesn’t work with less than 50% power). Similarly, if `-0.5 < lateral < 0.5`, the lateral boosters will not fire at all. If `lateral < -0.5`, the left booster will fire, and if `lateral > 0.5`, the right booster will fire. Again, the throttle scales affinely from 50% to 100% between -1 and -0.5 (and 0.5 and 1, respectively).
    
*   `gravity` dictates the gravitational constant, this is bounded to be within 0 and -12. Default is -10.0
    
*   `enable_wind` determines if there will be wind effects applied to the lander. The wind is generated using the function `tanh(sin(2 k (t+C)) + sin(pi k (t+C)))` where `k` is set to 0.01 and `C` is sampled randomly between -9999 and 9999.
    
*   `wind_power` dictates the maximum magnitude of linear wind applied to the craft. The recommended value for `wind_power` is between 0.0 and 20.0.
    
*   `turbulence_power` dictates the maximum magnitude of rotational wind applied to the craft. The recommended value for `turbulence_power` is between 0.0 and 2.0.
    

Version History[¶](#version-history "Link to this heading")
-----------------------------------------------------------

*   v3:
    
    *   Reset wind and turbulence offset (`C`) whenever the environment is reset to ensure statistical independence between consecutive episodes (related [GitHub issue](https://github.com/Farama-Foundation/Gymnasium/issues/954)).
        
    *   Fix non-deterministic behaviour due to not fully destroying the world (related [GitHub issue](https://github.com/Farama-Foundation/Gymnasium/issues/728)).
        
    *   Changed observation space for `x`, `y` coordinates from \\(\\pm 1.5\\) to \\(\\pm 2.5\\), velocities from \\(\\pm 5\\) to \\(\\pm 10\\) and angles from \\(\\pm \\pi\\) to \\(\\pm 2\\pi\\) (related [GitHub issue](https://github.com/Farama-Foundation/Gymnasium/issues/752)).
        
*   v2: Count energy spent and in v0.24, added turbulence with wind power and turbulence\_power parameters
    
*   v1: Legs contact with ground added in state vector; contact with ground give +10 reward points, and -10 if then lose contact; reward renormalized to 200; harder initial random push.
    
*   v0: Initial version
    

Notes[¶](#notes "Link to this heading")
---------------------------------------

There are several unexpected bugs with the implementation of the environment.

1.  The position of the side thrusters on the body of the lander changes, depending on the orientation of the lander. This in turn results in an orientation dependent torque being applied to the lander.
    
2.  The units of the state are not consistent. I.e.
    

*   The angular velocity is in units of 0.4 radians per second. In order to convert to radians per second, the value needs to be multiplied by a factor of 2.5.
    

For the default values of VIEWPORT\_W, VIEWPORT\_H, SCALE, and FPS, the scale factors equal: ‘x’: 10, ‘y’: 6.666, ‘vx’: 5, ‘vy’: 7.5, ‘angle’: 1, ‘angular velocity’: 2.5

After the correction has been made, the units of the state are as follows: ‘x’: (units), ‘y’: (units), ‘vx’: (units/second), ‘vy’: (units/second), ‘angle’: (radians), ‘angular velocity’: (radians/second)

Credits[¶](#credits "Link to this heading")
-------------------------------------------
