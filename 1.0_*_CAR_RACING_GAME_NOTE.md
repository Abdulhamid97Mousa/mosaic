
## Introduction

*   [Basic Usage](../../../introduction/basic_usage/)
*   [Training an Agent](../../../introduction/train_agent/)
*   [Create a Custom Environment](../../../introduction/create_custom_env/)
*   [Recording Agents](../../../introduction/record_agent/)
*   [Speeding Up Training](../../../introduction/speed_up_env/)
*   [Gym Migration Guide](../../../introduction/migration_guide/)

### API

*   [Env](../../../api/env/)
*   [Make and register](../../../api/registry/)
*   [Spaces](../../../api/spaces/)
    
    Toggle navigation of Spaces
    
    *   [Fundamental Spaces](../../../api/spaces/fundamental/)
    *   [Composite Spaces](../../../api/spaces/composite/)
    *   [Spaces Utils](../../../api/spaces/utils/)
*   [Wrappers](../../../api/wrappers/)
    
    Toggle navigation of Wrappers
    
    *   [List of Wrappers](../../../api/wrappers/table/)
    *   [Misc Wrappers](../../../api/wrappers/misc_wrappers/)
    *   [Action Wrappers](../../../api/wrappers/action_wrappers/)
    *   [Observation Wrappers](../../../api/wrappers/observation_wrappers/)
    *   [Reward Wrappers](../../../api/wrappers/reward_wrappers/)
*   [Vectorize](../../../api/vector/)
    
    Toggle navigation of Vectorize
    
    *   [Wrappers](../../../api/vector/wrappers/)
    *   [AsyncVectorEnv](../../../api/vector/async_vector_env/)
    *   [SyncVectorEnv](../../../api/vector/sync_vector_env/)
    *   [Utility functions](../../../api/vector/utils/)
*   [Utility functions](../../../api/utils/)
*   [Functional Env](../../../api/functional/)

### Environments

*   [Classic Control](../../classic_control/)
    
    Toggle navigation of Classic Control
    
    *   [Acrobot](../../classic_control/acrobot/)
    *   [Cart Pole](../../classic_control/cart_pole/)
    *   [Mountain Car Continuous](../../classic_control/mountain_car_continuous/)
    *   [Mountain Car](../../classic_control/mountain_car/)
    *   [Pendulum](../../classic_control/pendulum/)
*   [Box2D](../)
    
    Toggle navigation of Box2D
    
    *   [Bipedal Walker](../bipedal_walker/)
    *   [Car Racing](#)
    *   [Lunar Lander](../lunar_lander/)
*   [Toy Text](../../toy_text/)
    
    Toggle navigation of Toy Text
    
    *   [Blackjack](../../toy_text/blackjack/)
    *   [Taxi](../../toy_text/taxi/)
    *   [Cliff Walking](../../toy_text/cliff_walking/)
    *   [Frozen Lake](../../toy_text/frozen_lake/)
*   [MuJoCo](../../mujoco/)
    
    Toggle navigation of MuJoCo
    
    *   [Ant](../../mujoco/ant/)
    *   [Half Cheetah](../../mujoco/half_cheetah/)
    *   [Hopper](../../mujoco/hopper/)
    *   [Humanoid](../../mujoco/humanoid/)
    *   [Humanoid Standup](../../mujoco/humanoid_standup/)
    *   [Inverted Double Pendulum](../../mujoco/inverted_double_pendulum/)
    *   [Inverted Pendulum](../../mujoco/inverted_pendulum/)
    *   [Pusher](../../mujoco/pusher/)
    *   [Reacher](../../mujoco/reacher/)
    *   [Swimmer](../../mujoco/swimmer/)
    *   [Walker2D](../../mujoco/walker2d/)
*   [Atari](../../atari/)
*   [External Environments](../../third_party_environments/)

### Tutorials

*   [Gymnasium Basics](../../../tutorials/gymnasium_basics/)
    
    Toggle navigation of Gymnasium Basics
    
    *   [Make your own custom environment](../../../tutorials/gymnasium_basics/environment_creation/)
    *   [Handling Time Limits](../../../tutorials/gymnasium_basics/handling_time_limits/)
    *   [Implementing Custom Wrappers](../../../tutorials/gymnasium_basics/implementing_custom_wrappers/)
    *   [Load custom quadruped robot environments](../../../tutorials/gymnasium_basics/load_quadruped_model/)
*   [Training Agents](../../../tutorials/training_agents/)
    
    Toggle navigation of Training Agents
    
    *   [Action Masking in the Taxi Environment](../../../tutorials/training_agents/action_masking_taxi/)
    *   [Running the Experiment](../../../tutorials/training_agents/action_masking_taxi/#running-the-experiment)
    *   [Visualizing Results](../../../tutorials/training_agents/action_masking_taxi/#visualizing-results)
    *   [Results Analysis](../../../tutorials/training_agents/action_masking_taxi/#results-analysis)
    *   [Solving Blackjack with Tabular Q-Learning](../../../tutorials/training_agents/blackjack_q_learning/)
    *   [Solving Frozenlake with Tabular Q-Learning](../../../tutorials/training_agents/frozenlake_q_learning/)
    *   [Training using REINFORCE for Mujoco](../../../tutorials/training_agents/mujoco_reinforce/)
    *   [Speeding up A2C Training with Vector Envs](../../../tutorials/training_agents/vector_a2c/)
*   [Third-Party Tutorials](../../../tutorials/third-party-tutorials/)

### Development

*   [Github](https://github.com/Farama-Foundation/Gymnasium)
*   [Paper](https://arxiv.org/abs/2407.17032)
*   [Gymnasium Release Notes](../../../gymnasium_release_notes/)
*   [Gym Release Notes](../../../gym_release_notes/)
*   [Contribute to the Docs](https://github.com/Farama-Foundation/Gymnasium/blob/main/docs/README.md)

[Back to top](#)

Toggle Light / Dark / Auto color theme

Toggle table of contents sidebar

Car Racing[¶](#car-racing "Link to this heading")
=================================================

 [![../../../_images/car_racing.gif](../../../_images/car_racing.gif)](../../../_images/car_racing.gif) 

This environment is part of the Box2D environments which contains general information about the environment.

Action Space

`Box([-1. 0. 0.], 1.0, (3,), float32)`

Observation Space

`Box(0, 255, (96, 96, 3), uint8)`

import

`gymnasium.make("CarRacing-v3")`

Description[¶](#description "Link to this heading")
---------------------------------------------------

The easiest control task to learn from pixels - a top-down racing environment. The generated track is random every episode.

Some indicators are shown at the bottom of the window along with the state RGB buffer. From left to right: true speed, four ABS sensors, steering wheel position, and gyroscope. To play yourself (it’s rather fast for humans), type:

python gymnasium/envs/box2d/car\_racing.py

Remember: it’s a powerful rear-wheel drive car - don’t press the accelerator and turn at the same time.

Action Space[¶](#action-space "Link to this heading")
-----------------------------------------------------

If continuous there are 3 actions :

*   0: steering, -1 is full left, +1 is full right
    
*   1: gas
    
*   2: braking
    

If discrete there are 5 actions:

*   0: do nothing
    
*   1: steer right
    
*   2: steer left
    
*   3: gas
    
*   4: brake
    

Observation Space[¶](#observation-space "Link to this heading")
---------------------------------------------------------------

A top-down 96x96 RGB image of the car and race track.

Rewards[¶](#rewards "Link to this heading")
-------------------------------------------

The reward is -0.1 every frame and +1000/N for every track tile visited, where N is the total number of tiles visited in the track. For example, if you have finished in 732 frames, your reward is 1000 - 0.1\*732 = 926.8 points.

Starting State[¶](#starting-state "Link to this heading")
---------------------------------------------------------

The car starts at rest in the center of the road.

Episode Termination[¶](#episode-termination "Link to this heading")
-------------------------------------------------------------------

The episode finishes when all the tiles are visited. The car can also go outside the playfield - that is, far off the track, in which case it will receive -100 reward and die.

Arguments[¶](#arguments "Link to this heading")
-----------------------------------------------

\>>> import gymnasium as gym
\>>> env \= gym.make("CarRacing-v3", render\_mode\="rgb\_array", lap\_complete\_percent\=0.95, domain\_randomize\=False, continuous\=False)
\>>> env
<TimeLimit<OrderEnforcing<PassiveEnvChecker<CarRacing<CarRacing-v3>>>>>

*   `lap_complete_percent=0.95` dictates the percentage of tiles that must be visited by the agent before a lap is considered complete.
    
*   `domain_randomize=False` enables the domain randomized variant of the environment. In this scenario, the background and track colours are different on every reset.
    
*   `continuous=True` specifies if the agent has continuous (true) or discrete (false) actions. See action space section for a description of each.
    

Reset Arguments[¶](#reset-arguments "Link to this heading")
-----------------------------------------------------------

Passing the option `options["randomize"] = True` will change the current colour of the environment on demand. Correspondingly, passing the option `options["randomize"] = False` will not change the current colour of the environment. `domain_randomize` must be `True` on init for this argument to work.

\>>> import gymnasium as gym
\>>> env \= gym.make("CarRacing-v3", domain\_randomize\=True)

\# normal reset, this changes the colour scheme by default
\>>> obs, \_ \= env.reset()

\# reset with colour scheme change
\>>> randomize\_obs, \_ \= env.reset(options\={"randomize": True})

\# reset with no colour scheme change
\>>> non\_random\_obs, \_ \= env.reset(options\={"randomize": False})

Version History[¶](#version-history "Link to this heading")
-----------------------------------------------------------

*   v2: Change truncation to termination when finishing the lap (1.0.0)
    
*   v1: Change track completion logic and add domain randomization (0.24.0)
    
*   v0: Original version
    

References[¶](#references "Link to this heading")
-------------------------------------------------

*   Chris Campbell (2014), http://www.iforce2d.net/b2dtut/top-down-car.
    
