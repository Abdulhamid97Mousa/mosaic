"""Command-line interface for Ray RLlib multi-agent worker.

This module provides the CLI entry point for launching multi-agent training
with Ray RLlib. It's invoked by the MOSAIC TrainerDispatcher.

Usage:
    python -m ray_worker.cli --config /path/to/config.json

    # Or using the installed entry point:
    ray-worker --config /path/to/config.json

The config file should contain the training configuration in JSON format,
either as a direct RayWorkerConfig or nested under metadata.worker.config
(as generated by the UI).
"""

from __future__ import annotations

import argparse
import json
import logging
import sys
from pathlib import Path
from typing import Optional

from .config import RayWorkerConfig, load_worker_config
from .runtime import RayWorkerRuntime

_LOGGER = logging.getLogger(__name__)


def setup_logging(verbose: bool = False) -> None:
    """Set up logging configuration.

    Args:
        verbose: If True, set DEBUG level; otherwise INFO
    """
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
        stream=sys.stdout,
    )


def create_parser() -> argparse.ArgumentParser:
    """Create the argument parser for the CLI.

    Returns:
        Configured argument parser
    """
    parser = argparse.ArgumentParser(
        prog="ray-worker",
        description="Ray RLlib multi-agent training worker for MOSAIC",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Train with config file
  python -m ray_worker.cli --config var/trainer/runs/my_run/config.json

  # Train with verbose output
  python -m ray_worker.cli --config config.json --verbose

  # Dry run (validate config only)
  python -m ray_worker.cli --config config.json --dry-run
        """,
    )

    parser.add_argument(
        "--config",
        type=str,
        required=True,
        help="Path to JSON configuration file",
    )

    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        default=False,
        help="Enable verbose (DEBUG) logging",
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        default=False,
        help="Validate configuration without running training",
    )

    parser.add_argument(
        "--output-dir",
        type=str,
        default=None,
        help="Override output directory from config",
    )

    # gRPC telemetry arguments (for compatibility with dispatcher)
    parser.add_argument(
        "--grpc",
        action="store_true",
        default=False,
        help="Enable gRPC telemetry handshake (reserved for future use)",
    )

    parser.add_argument(
        "--grpc-target",
        type=str,
        default="127.0.0.1:50055",
        help="gRPC target host:port (reserved for future use)",
    )

    parser.add_argument(
        "--worker-id",
        type=str,
        default="ray_worker",
        help="Worker identifier for distributed runs",
    )

    return parser


def validate_config(config: RayWorkerConfig) -> bool:
    """Validate the configuration.

    Args:
        config: Configuration to validate

    Returns:
        True if valid, False otherwise
    """
    errors = []

    if not config.run_id:
        errors.append("run_id is required")

    if not config.environment.family:
        errors.append("environment.family is required")

    if not config.environment.env_id:
        errors.append("environment.env_id is required")

    if config.training.total_timesteps <= 0:
        errors.append("training.total_timesteps must be positive")

    if config.resources.num_workers < 0:
        errors.append("resources.num_workers must be non-negative")

    if errors:
        for error in errors:
            _LOGGER.error(f"Configuration error: {error}")
        return False

    return True


def print_config_summary(config: RayWorkerConfig) -> None:
    """Print a summary of the configuration.

    Args:
        config: Configuration to summarize
    """
    # Get batch size from algo_params (dynamic parameters)
    batch_size = config.training.algo_params.get('train_batch_size', 4000)

    print("=" * 60)
    print("Ray RLlib Multi-Agent Training Configuration")
    print("=" * 60)
    print(f"Run ID:         {config.run_id}")
    print(f"Environment:    {config.environment.family}/{config.environment.env_id}")
    print(f"API Type:       {config.environment.api_type.value}")
    print(f"Paradigm:       {config.paradigm.value}")
    print(f"Algorithm:      {config.training.algorithm}")
    print(f"Total Steps:    {config.training.total_timesteps:,}")
    print(f"Batch Size:     {batch_size}")
    print(f"Workers:        {config.resources.num_workers}")
    print(f"GPUs:           {config.resources.num_gpus}")
    print(f"Output Dir:     {config.output_dir}")
    print(f"Checkpoint Dir: {config.checkpoint_dir}")
    print(f"TensorBoard:    {config.tensorboard}")
    print(f"WandB:          {config.wandb}")
    print("=" * 60)
    sys.stdout.flush()


def main(argv: Optional[list[str]] = None) -> int:
    """Main entry point for the CLI.

    Args:
        argv: Command line arguments (defaults to sys.argv)

    Returns:
        Exit code (0 for success, non-zero for failure)
    """
    parser = create_parser()
    args = parser.parse_args(argv)

    setup_logging(verbose=args.verbose)

    # Load configuration
    config_path = Path(args.config)
    if not config_path.exists():
        _LOGGER.error(f"Configuration file not found: {config_path}")
        print(f"[ERROR] config_file_not_found path={config_path}")
        return 1

    try:
        config = load_worker_config(str(config_path))
    except Exception as e:
        _LOGGER.error(f"Failed to load configuration: {e}")
        print(f"[ERROR] config_load_failed error={e}")
        return 1

    # Override output directory if specified
    if args.output_dir:
        # Create a new config with updated output_dir
        config = RayWorkerConfig(
            run_id=config.run_id,
            environment=config.environment,
            paradigm=config.paradigm,
            training=config.training,
            resources=config.resources,
            checkpoint=config.checkpoint,
            output_dir=args.output_dir,
            seed=config.seed,
            tensorboard=config.tensorboard,
            tensorboard_dir=config.tensorboard_dir,
            wandb=config.wandb,
            wandb_project=config.wandb_project,
            wandb_entity=config.wandb_entity,
            wandb_run_name=config.wandb_run_name,
            fastlane_enabled=config.fastlane_enabled,
            fastlane_throttle_ms=config.fastlane_throttle_ms,
            extras=config.extras,
        )

    # Validate configuration
    if not validate_config(config):
        print("[ERROR] config_validation_failed")
        return 1

    # Print configuration summary
    print_config_summary(config)

    # Dry run mode
    if args.dry_run:
        _LOGGER.info("Dry run mode - configuration is valid")
        print("[DRY_RUN] config_valid=true")
        return 0

    # Run training
    try:
        print(f"[START] run_id={config.run_id}")
        sys.stdout.flush()

        runtime = RayWorkerRuntime(config)
        result = runtime.run()

        _LOGGER.info("Training completed successfully")
        return 0

    except KeyboardInterrupt:
        _LOGGER.warning("Training interrupted by user")
        print(f"[INTERRUPTED] run_id={config.run_id}")
        return 130  # Standard exit code for SIGINT

    except Exception as e:
        _LOGGER.error(f"Training failed: {e}", exc_info=True)
        print(f"[FAILED] run_id={config.run_id} error={e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
