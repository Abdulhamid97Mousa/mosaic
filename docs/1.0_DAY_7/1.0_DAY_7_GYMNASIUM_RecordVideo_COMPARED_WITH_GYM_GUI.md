# Day 7 — Gymnasium `RecordVideo` vs. `gym_gui`

## Executive snapshot

- **`RecordVideo` is a deterministic episodic recorder.** It piggybacks on Gymnasium's render pipeline, intercepting `env.render()` frames and muxing them into MP4 chunks keyed by episode.
- **`gym_gui` is an event-driven visualization stack.** It converts structured telemetry—including pixels—from adapters into Qt widgets, storage backends, and replay panes.
- **Overlap exists only at the frame payload boundary.** Both systems observe the same rendered frames, but `gym_gui` prioritizes live interaction and metadata-rich telemetry while `RecordVideo` targets archive-quality episode dumps.
- **The integration sweet spot:** let `RecordVideo` produce canonical MP4 assets while `gym_gui` focuses on low-latency UI updates and replay services referencing those assets.

## Gymnasium `RecordVideo` wrapper — what it actually does

| Dimension | Details |
| --- | --- |
| **Trigger** | Wraps an environment; every call to `step()` schedules a check via `render_on_step`. Uses `episode_trigger` and `step_trigger` callables to decide when to start/stop recording. |
| **Frame capture** | Calls the wrapped env with `mode="rgb_array"`. Assumes the env supports that render mode or a `render_frame()` fallback. |
| **Encoding** | Uses `moviepy`/`imageio-ffmpeg` to assemble frames into MP4 chunks stored under `"videos/"` relative to `video_folder`. Filenames include episode indices and timestamps. |
| **Batching** | Buffers raw frames until an episode terminates, then writes them synchronously (blocking the main loop). Optionally resets the underlying env if `disable_logger` is false. |
| **Metadata** | Writes a sidecar JSON containing episode timestamps and trigger configuration; does **not** track rewards, actions, or custom telemetry. |
| **Operational costs** | CPU bound during encoding; extra RAM used to buffer frames per episode. No GPU acceleration by default. |

### Strengths to lean on

1. **Zero-configuration capture**: Works with any Gymnasium environment that exposes `rgb_array`.
2. **Battle-tested pipeline**: Downstream tooling (CleanRL, W&B) already expects the MP4 layout produced by `RecordVideo`.
3. **Simple toggles**: Trigger callables make it easy to restrict recordings (e.g., every Nth episode, warmup only, evaluation only).

### Constraints you cannot ignore

1. **Render-mode dependency**: If our adapter currently serves Qt widgets via shared memory or local textures without exposing `rgb_array`, `RecordVideo` becomes a no-op.
2. **Blocking write**: Long episodes block the control loop during encoding—problematic for real-time UI responsiveness.
3. **No telemetry awareness**: Frame dumps are blind to action/reward metadata, so Cam + Chart synchronization must be added by us.

## `gym_gui` rendering + telemetry stack — current shape

| Component | Current behavior | Risks / Hooks for capture |
| --- | --- | --- |
| **Renderer strategies (`rendering/interfaces.py`)** | Protocol-driven Qt widgets keyed by `RenderMode`. Consume structured payloads (`Mapping[str, object]`) emitted by adapters. | We can extend payload schema with `frame_buffer` or `video_uri` fields to surface `RecordVideo` outputs. |
| **Adapters (`core/adapters/*`)** | Convert Gymnasium env outputs into strongly typed dataclasses. Rendering payloads already include `np.ndarray` frames for certain games. | Need a standard `rgb_array` export path to feed both RecordVideo and Qt strategies without duplication. |
| **Session telemetry (`services/telemetry.py`, `runtime/data/episodes/*`)** | Persists `StepRecord` + `EpisodeRollup` to JSONL/SQLite. Supports replay + diffing. | No first-class binary/video storage; referencing MP4 paths requires schema extension. |
| **UI replay tabs (`ui/widgets/render_tabs.py`)** | Multi-pane viewer that listens to the telemetry bus and renders via strategies. | Adding playback controls for MP4 assets must avoid blocking Qt's event loop—likely spawn a worker thread. |

### Strengths we already have

1. **Structured metadata**: Every step carries rewards, actions, and agent IDs—perfect companion to detached video files.
2. **Service locator orchestration**: We can register a `VideoArtifactService` once and reuse it across controllers, telemetry, and storage recorders.
3. **Qt-centric UX**: Live overlays, annotations, and debug panels are already idiomatic in our stack.

### Gaps still open

1. **Unified frame source**: Render payloads and MP4 capture share no contract today; adapters often transform `rgb_array` into Qt-friendly pixmaps inline.
2. **Binary asset storage policy**: Runtime storage is JSONL/SQLite only; we need a retention strategy for MP4 (naming, pruning, linking to episodes).
3. **Background encoding**: The GUI must remain responsive even while writing large videos.

## Head-to-head comparison

| Capability | `RecordVideo` | `gym_gui` | Integration commentary |
| --- | --- | --- | --- |
| **Purpose** | Offline episodic capture. | Live visualization + telemetry persistence. | Complementary—use RecordVideo for archival, GUI for insight. |
| **Data richness** | Pixels only + minimal JSON sidecar. | Rewards, actions, agent tags, env metadata. | Need to link RecordVideo filenames into telemetry rows. |
| **Performance profile** | Encoding blocks the main thread. | Qt event loop, low-latency. | Offload RecordVideo writes into background tasks triggered by telemetry events. |
| **Configurability** | Trigger callables, output folder, file naming. | Render strategies, UI layouts, telemetry sinks. | Expose trigger knobs in GUI preferences so users can toggle capture without touching Python code. |
| **Dependencies** | `moviepy`, `imageio-ffmpeg`. | Qt stack + numpy + storage services. | Ensure those deps are present in our runtime (they already are via Gymnasium). |
| **Distribution** | MP4 + JSON in `videos/`. | JSONL + SQLite in `runtime/data`. | Introduce `runtime/data/videos/` and cross-reference via telemetry IDs. |

## Integration playbook (contrarian slant)

1. **Stop trying to rebuild a recorder inside Qt.** Double down on `RecordVideo` for the raw capture. Anything else is sunk cost and re-implements Gym's reliable pipeline.
2. **Force adapters to expose `rgb_array` first.** If an environment can't render to array, don't launch the GUI—fail fast. That pressure keeps adapters honest and simplifies debugging.
3. **Wire a `VideoArtifactService`.** Responsibilities: invoke `RecordVideo`, stash MP4 paths, emit telemetry events linking episode IDs → video URI, and prune old assets per storage profiles.
4. **Teach the GUI to stream MP4 lazily.** Instead of pushing raw frames, let replay widgets open the file via `QMediaPlayer` or `opencv` only when the user scrubs. Keep the live view untouched.
5. **Surface controls in the UI.** Add a "Capture episodes" toggle + frequency dropdown that writes trigger config into the session bootstrap so `RecordVideo` honors user intent.

## Contrarian guidance for the current GUI stage

- **Freeze new UI chrome.** Every pixel spent on new widgets without settling the video + telemetry story just deepens technical debt. Channel design time into the data plumbing first.
- **Rip out bespoke frame buffers.** Wherever the GUI converts numpy arrays to Qt pixmaps directly inside controllers, replace it with a shared utility that both the live view and `RecordVideo` consume. Duplicated conversions are bugs-in-waiting.
- **Delay actor automation demos.** Automated agents without reliable capture metrics are vanity projects. Ship the capture pipeline, then let actors prove themselves with repeatable evidence.
- **Instrument everything.** Add timing probes around widget updates vs. video writes. If GUI latency spikes during encoding, you have hard data to justify asynchronous refactors.
- **Plan for asset hygiene.** Set hard quotas (e.g., keep the latest 50 MP4s) and implement pruning now. Otherwise the GUI becomes a storage leak the first time someone runs a long batch.

## Contrarian replay pivot

Treat the GUI as a telemetry-first shell and outsource heavy capture work:

- Lean on Gymnasium's `RecordVideo` to emit MP4s per episode; it's already a dependable recorder.
- Let telemetry reference those MP4s—store the file path or artifact identifier alongside each episode so replay widgets can pull them on demand.
- Reserve in-memory frames for short-lived overlays or ultra-low-latency live views, then release them as soon as the video artifact lands on disk.

You're not abandoning replay—you are splitting responsibilities. Keep the responsive in-memory view for moment-to-moment feedback, while promoting persistent video artifacts to first-class citizens so the GUI no longer has to hoard every frame it might revisit later.

### Implementation blueprint

1. **Bootstrap `RecordVideo` alongside environment creation.**
	- Extend `SessionController.load_environment` to wrap adapters' Gymnasium envs with `RecordVideo` when capture is enabled.
	- Choose trigger defaults (`episode_trigger=lambda ep: ep % 5 == 0`) and expose them through the existing session config dataclasses.
	- Route `video_folder` into `runtime/data/videos/<session_id>/` to keep artifacts segregated per run.

2. **Publish video artifacts via telemetry.**
	- Modify `TelemetryService` to accept an optional `video_path` in `EpisodeRollup`.
	- After `RecordVideo` finalizes an MP4, emit a `TelemetryEvent.VideoAvailable` with metadata (episode index, checksum, path).
	- Update storage writers (`StorageRecorderService` JSONL + SQLite store) to persist the new field.

3. **Thin the live frame cache.**
	- Introduce a `FrameCachePolicy` in `SessionController` that keeps only the latest `N` frames (e.g., 5) per renderer.
	- Once a `VideoAvailable` event arrives, purge the historical frames for that episode, retaining only summary thumbnails.

4. **Teach the UI to lazy-load MP4s.**
	- Add a `VideoPlaybackPresenter` that receives telemetry events and opens MP4s via `QMediaPlayer` in a background thread.
	- In `render_tabs.py`, show a "Play recording" button when `video_path` exists; clicking streams the MP4 rather than iterating over cached numpy arrays.
	- Provide scrub controls driven by media timestamps instead of step indices; map timestamps back to telemetry entries for overlays.

5. **Automate retention and hygiene.**
	- Extend `StorageRecorderService` profile configs with a `max_videos_per_session` limit and an eviction strategy (LRU by completion time).
	- Implement a pruning job triggered at session end that deletes oldest MP4s beyond the quota and updates telemetry records accordingly.

6. **Expose controls to users.**
	- Surface capture toggles in both CLI flags and the settings pane, writing preferences into `settings.py`.
	- Allow users to choose trigger cadence (every episode, eval-only, manual) and to request immediate deletion of existing artifacts.

This path keeps the GUI nimble while ensuring every episode worth revisiting lives as a durable artifact, with telemetry acting as the index that stitches metrics, overlays, and video together on demand.

## Next concrete steps (short list)

1. Refactor adapters to emit a canonical `FramePayload` dataclass containing both Qt pixmaps and raw `rgb_array` buffers.
2. Implement a `RecordVideoOrchestrator` that subscribes to session lifecycle hooks, runs recordings in a worker, and publishes MP4 paths to `TelemetryService`.
3. Extend telemetry schemas (`StepRecord`, `EpisodeRollup`) with optional `video_path` fields and update storage writers.
4. Update the GUI replay tab to show a "Play episode video" button when a `video_path` exists, deferring playback to a non-blocking media widget.
5. Add configuration knobs (CLI flags + UI toggle) to control `RecordVideo` triggers without touching code.
